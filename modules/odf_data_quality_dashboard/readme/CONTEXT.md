The primary business need for this module is to streamline and accelerate data import processes. In many data migration or integration scenarios, a single invalid record (e.g., a contact with an incorrect VAT number) can cause an entire import batch to fail. This creates a bottleneck and requires technical intervention to fix the data and re-run the import.

This module solves that problem by adopting a non-blocking approach. Data is imported first, ensuring speed and efficiency. A separate, automated process then runs nightly to check for common data quality issues. These issues are flagged and presented in a user-friendly dashboard, transforming data validation from a blocking, technical task into a manageable, asynchronous workflow for functional users. This ensures that the data import pipeline remains fast and resilient, while still providing a robust mechanism for maintaining high data quality.
